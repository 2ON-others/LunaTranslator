## Как использовать офлайн-перевод с большой моделью?

### Sakura Large Model

> Рекомендуется для использования, простая настройка, хорошие результаты, также может работать на чистом CPU с легкой моделью.

Методы развертывания

1. [Развертывание SakuraLLM на онлайн-платформе GPU](/zh/sakurallmcolab.md)

2. Другие методы развертывания можно найти на https://github.com/SakuraLLM/SakuraLLM/wiki

### Совместимый с ChatGPT интерфейс

Можно использовать адрес и модель **Sakura Large Model** в параметрах этого интерфейса (по сравнению с этим просто добавлены некоторые предварительно заданные prompt и другие параметры, других отличий нет).

Также можно использовать такие инструменты, как [TGW](https://github.com/oobabooga/text-generation-webui), [llama.cpp](https://github.com/ggerganov/llama.cpp), [ollama](https://github.com/ollama/ollama), [one-api](https://github.com/songquanpeng/one-api), для развертывания модели, а затем ввести адрес и модель.

Также можно использовать платформы, такие как Kaggle, для развертывания модели в облаке, в этом случае может потребоваться SECRET_KEY, в других случаях можно игнорировать параметр SECRET_KEY.

Также можно ввести API зарегистрированной большой модели (но это не обязательно), по сравнению с зарегистрированным онлайн-переводом с совместимым с ChatGPT интерфейсом, единственное отличие заключается в том, что не будет использоваться прокси.